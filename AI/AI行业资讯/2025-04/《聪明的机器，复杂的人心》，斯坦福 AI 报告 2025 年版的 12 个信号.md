## 《聪明的机器，复杂的人心》，斯坦福 AI 报告 2025 年版的 12 个信号

斯坦福出了最新的 AI 报告，我们一起来看一下核心思想，或者会给我们新的启示...如果你对 AI 感兴趣、但不想啃上百页的英文报告，这篇总结可以帮你 10 分钟看懂[《斯坦福 AI 指数 2025》](https://zhida.zhihu.com/search?content_id=256259611&content_type=Article&match_order=1&q=%E3%80%8A%E6%96%AF%E5%9D%A6%E7%A6%8FAI%E6%8C%87%E6%95%B02025%E3%80%8B&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ1NDYwODUsInEiOiLjgIrmlq_lnabnpo9BSeaMh-aVsDIwMjXjgIsiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTYyNTk2MTEsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.pl0UeMjJWmqivQ7JjQuJmyoVs_98vo1X7YIW9e5pM40&zhida_source=entity)。

![](https://pica.zhimg.com/v2-867ec796ad57172b749d91b066018f9a_1440w.jpg)

## 一句话：

AI 从“未来技术”彻底变成了“当下系统”。它不仅影响工作和生活，还在重塑教育、治理、信任乃至能源结构。

### 01 ｜ AI，不再是“遥远未来”的科技词

斯坦福刚发布的《2025 年 AI 指数报告》用一连串令人咋舌的数据告诉我们：AI 不只是“有用”，它正成为社会结构的一部分。

比如，美国在 2024 年对 AI 的私人投资达到 1091 亿美元，是中国的近 12 倍。而 AI 驱动的医疗设备，仅 2023 年一年，美国 FDA 就批准了 223 种。这不是趋势，这是浪潮。

### 02 ｜从写代码到看病，AI 表现越来越像“专家”

这一年，AI 在很多能力测试中“超神”了。比如，在国际数学奥林匹克模拟考试中，[OpenAI](https://zhida.zhihu.com/search?content_id=256259611&content_type=Article&match_order=1&q=OpenAI&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ1NDYwODUsInEiOiJPcGVuQUkiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTYyNTk2MTEsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.fkknh4I7lJdmxNLdhyBk77f8Rf7BJjUWe-uqc0FHIHM&zhida_source=entity)的新模型得了 74.4% 的高分，而[GPT-4](https://zhida.zhihu.com/search?content_id=256259611&content_type=Article&match_order=1&q=GPT-4&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ1NDYwODUsInEiOiJHUFQtNCIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjI1NjI1OTYxMSwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.I8Pq3WOlL4fSBzMZGp6fdhZrkQgN-N_fpFsU8k9imjA&zhida_source=entity)o 只有 9.3%。甚至还有 AI 在编程任务中比专业程序员更快更准。

医学领域也不例外。GPT-4 在多个临床诊断任务中超过了人类医生，包括癌症识别和高危病人预警——听起来有点让人后背发凉对吧？但研究还发现，人机协作效果更好，这可能才是未来的常态。

### 03 ｜便宜、快、全球可用——AI 的“平民化”时代来了

过去，运行一个像 GPT-3.5 那样的模型，每处理 100 万个词，要花 20 美元；现在，最新的开源模型只要 7 美分，整整便宜了 280 多倍！

也就是说，越来越多的小公司、初创团队，甚至学生个人，也有机会用上高性能 AI。这种“民主化”的技术扩散，不仅降低了门槛，也加快了全球 AI 竞赛的节奏。

但你有没有想过：当 AI“谁都能用”的那天来临，我们是否也该重新思考“谁来负责”？

### 04 ｜“高质量模型”越来越多，AI 的天花板在哪里？

2024 年，全球有 90% 的先进 AI 模型来自企业。你没看错，不是大学实验室，不是国家研究院，而是 OpenAI、Google、Meta 这些科技巨头。学术界则在产出“最有影响力”的研究文章方面依然独占鳌头。

这背后是疯狂的资金投入，也是令人侧目的“卷”。AI 模型每 5 个月就要翻倍地扩展计算规模，数据量每 8 个月翻一轮。说得俗点：这是用电、用钱、用数据堆出来的“超级聪明脑”。

问题来了：模型越来越强，谁来设定边界？谁来负责用它的人？

---

### 05 ｜开源模型崛起：从“吊车尾”到“直逼头部玩家”

去年的报告还在说：开源 AI 落后于封闭模型。可今年，差距就缩小到不到 2%。这意味着，哪怕你不是大厂工程师，也有可能调教出一个性能媲美 GPT-4 的小模型。

而这件事最打动我的，是一种“权力的再分配”：技术不再被少数人掌控。开源不仅意味着人人可用，更可能是一种透明、审慎且民主的科技实践。

当然，问题也随之而来：谁来审核这些模型？一旦被滥用，怎么办？

---

### 06 ｜“AI 事故”正在增多，但“责任”仍然模糊

2024 年被记录在案的 AI 相关事故达到 233 起，比上一年增长了 56%。而且，几乎没有统一的“责任认定机制”。

你会发现一个吊诡的现象：企业一边在大谈“负责任的 AI”，一边却很少真正在模型发布前做安全测试。新的[RAI](https://zhida.zhihu.com/search?content_id=256259611&content_type=Article&match_order=1&q=RAI&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ1NDYwODUsInEiOiJSQUkiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTYyNTk2MTEsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.p1coxHdQjho0ARBQTx50O-KonlYsHXuzIdyys1bkk54&zhida_source=entity)（负责任 AI）评估标准虽然不断推出，比如[HELM Safety](https://zhida.zhihu.com/search?content_id=256259611&content_type=Article&match_order=1&q=HELM+Safety&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ1NDYwODUsInEiOiJIRUxNIFNhZmV0eSIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjI1NjI1OTYxMSwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.Y_uyAnzspswEoQeNFxdLgaDiTchoBgDjcVn6L4JmsKc&zhida_source=entity)和[FACTS](https://zhida.zhihu.com/search?content_id=256259611&content_type=Article&match_order=1&q=FACTS&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ1NDYwODUsInEiOiJGQUNUUyIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjI1NjI1OTYxMSwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.x9Q7ZyW5fc0IHGiLARVRToXHT7zpKXl7mNI-hgsQwY4&zhida_source=entity)，但使用它们的机构寥寥无几。

是不是听起来有点像小时候老师说“安全第一”，可我们却从没上过一节真正的安全教育课？

### 07 ｜ AI+ 科学：诺奖得主都开始站台了

过去一年，AI 在科学界可谓风光无限：不仅两个诺贝尔奖都颁给了 AI 相关研究者（一个是神经网络理论，一个是蛋白质折叠预测），OpenAI 还推出了能“做实验”的 AI 助手。

科学家用 AI 筛药、预测森林火灾，甚至连蛋白质数据库都增长了数倍。医学上，AI 生成的“合成数据”也被用来保护隐私、改善预测、加速药物研发。

听起来很炫对吧？但我总觉得这背后有种不安——如果 AI 变成实验室的“新老板”，我们是否还保有足够的判断力？

---

### 08 ｜ AI 教育大飞越，也暴露了巨大“认知缺口”

全球已经有 2/3 的国家将计算机科学教育纳入中小学课程。但你知道吗？在非洲，很多学校连稳定供电都没有；在美国，尽管 81% 的 CS 老师认为应该教 AI，真正有信心教的却不到一半。

这不是“AI 教得够不够”，而是“人有没有准备好”的问题。我们花了几十年建立的教育体系，似乎被 AI 轻轻一推就乱了阵脚。

教育的反应，总是比技术慢半拍。而这一拍，很可能决定了一代人的“信息权”。

---

### 09 ｜普通人对 AI 的感受，远比你以为的复杂

斯坦福的报告统计了 26 个国家对 AI 的态度：中国、印尼、泰国的乐观比例超过 77%，而美加英这些科技强国，竟然只有三成多的民众觉得 AI 是“利大于弊”。

这不是谁更聪明，而是谁更担心失控。发达国家看多了深度伪造、数据泄露，也更敏感“透明与公平”；而发展中国家更关注“能不能用上”，看重效率与机会。

AI 就像水银：你掌握得越多，越容易察觉它的流动不受控制。

### 10 ｜当 AI 比你“还像人”，我们该如何自处？

AI 已经在多项任务中超过人类，但讽刺的是，它在最基础的“复杂推理”上却屡屡出错。像 PlanBench 这种逻辑题，AI 依旧常常“翻车”。

为什么？或许因为 AI 并没有“理解”，它只是在预测。它能背诵千本书，但不一定能解决一个现实生活的“多选题”。

所以问题来了：**当 AI 越来越像人，我们会不会反而失去对“人”的珍惜？**

### 11 ｜ AI 治理：各国都在“加快立规”，但方向各异

2024 年，全球共有 75 个国家在立法中提到 AI，比上一年增长 21.3%。美国联邦出台了 59 条 AI 相关法规，比 2023 年翻了一倍；中国、法国、沙特、印度都分别斥巨资建立国家 AI 基础设施。

但问题在于：这些法规和策略，彼此之间缺乏统一标准。比如对“深度伪造”的定义、AI 透明度的要求、训练数据的合规性……都五花八门。

就像各国都在建高速公路，却没人商量“靠右开还是靠左开”。

---

### 12 ｜能源焦虑浮出水面：AI 越来越“烧电”，环保压力爆表

你可能想不到，训练 GPT-4 这种大型模型，碳排放是 5884 吨——相当于一个美国人 300 年的排放量。

而 2024 年发布的[Llama 3.1](https://zhida.zhihu.com/search?content_id=256259611&content_type=Article&match_order=1&q=Llama+3.1&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ1NDYwODUsInEiOiJMbGFtYSAzLjEiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTYyNTk2MTEsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.f2GW6PO52YLfKCYZrZEiOjz8UAlDyhudyHOsTOt9VE8&zhida_source=entity)（405B 参数）排放更是高达 8930 吨！这一趋势正在引起全球科技公司的“能源恐慌”：微软甚至宣布重启废弃核电站来供电；谷歌、亚马逊也在抢购清洁能源项目。

AI 技术虽然“轻盈灵巧”，但背后可能是巨大的能源账单。**当 AI 越来越“绿色难保”，我们是否也要重新思考：进步的代价究竟该由谁来买单？**

> 来源：知乎
