# 百度飞桨框架 3.0 正式版发布

2025-04-02 12:54:00

4 月 1 日，深度学习平台飞桨宣布新一代飞桨框架 3.0 正式发布，以“动静统一自动并行”等五大核心技术创新为大模型训推提速。

作为大模型时代的 Infra“基础设施”，深度学习框架的重要性愈发凸显，大模型训练、推理等任务都离不开深度学习框架的优化与支撑。

飞桨框架 3.0 从设计理念上实现了从底层硬件适配到顶层开发体验的全面进化，在训练效率、性能、兼容性等关键指标上建立了新标杆。其中，“动静统一自动并行”、“大模型训推一体“、“科学计算高阶微分”、“神经网络编译器”、“异构多芯适配”这五大技术新特性，系统性解决了当前大模型产业面临的训练成本高、推理效率低、硬件适配难等核心痛点。

飞桨提出的"动静统一自动并行"技术，大幅降低大模型开发训练成本，让算法创新回归核心价值创造；同时，"训推一体"设计理念打破了训练与推理的割裂状态，通过全方位深度优化，飞桨框架 3.0 能够支持众多开源大模型进行高性能推理，并在 DeepSeek V3/R1 上取得了突出的性能表现。

目前，飞桨框架 3.0 支持文心 4.5、文心 X1 等多款主流大模型，DeepSeek-R1 满血版单机部署吞吐提升一倍。通过技术算法创新，飞桨让低时延、高吞吐、低算力成本的推理服务成为了现实。

同时，在科学智能领域，飞桨框架 3.0 锚定科学前沿探索需要，提升微分方程求解速度。通过高阶自动微分和神经网络编译器技术，加速微分方程求解，速度比 PyTorch 开启编译器优化后的 2.6 版本平均快 115%。飞桨还对 DeepXDE、Modulus 等主流开源科学计算工具进行了广泛适配，并成为 DeepXDE 的默认推荐后端。其展现的科学智能潜力在气象预测、生命科学、航空航天等领域具有广泛的应用价值。

此外，在运算速度上，借助创新研制的神经网络编译器 CINN，实现性能的显著提升，部分算子执行速度提升 4 倍，模型端到端训练速度提升 27.4%。

在硬件适配方面，飞桨框架 3.0 推出了多芯片统一适配方案，构建"一次开发，全栈部署"的生态体系。目前已支持 60 余款主流芯片，覆盖训练集群、自动驾驶、智能终端等场景，开发者只需编写一份代码即可实现跨芯片无缝迁移，硬件适配成本直降 80%。

截至 2024 年 10 月，飞桨文心生态已凝聚 1808 万开发者，服务了 43 万家企事业单位，创建了 101 万个模型。

> 来源：新华网
